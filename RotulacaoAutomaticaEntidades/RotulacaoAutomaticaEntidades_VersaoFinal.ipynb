{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# from spacy.tokenizer import Tokenizer\n",
    "import nltk.data\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "from nltk import FreqDist\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import pickle\n",
    "import itertools\n",
    "import glob\n",
    "from iteration_utilities import duplicates\n",
    "from iteration_utilities import unique_everseen\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "from util import tokenizeAn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do dataset de treinamento 129380\n"
     ]
    }
   ],
   "source": [
    "dataset_treinamento = pd.read_csv(\"dataset_treinamento.csv\", usecols=['Palavras', 'Rotulo', 'Sentenca', 'Inicio', 'Fim', 'Documento'], encoding='utf-8')\n",
    "print(\"Tamanho do dataset de treinamento\",len(dataset_treinamento))\n",
    "dataset_treinamento =dataset_treinamento[0:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantida de de sentenças no dataSet utilizado na rotulação manual: 13628\n"
     ]
    }
   ],
   "source": [
    "#Esse arquivo é utilizado para extrairmos as setenças a que cada token rotulado no dataset pertence. É utilizado pelo\n",
    "# pela célula de código a seguir\n",
    "with open(\"dataset_para_rotulacao_manual_versao_2.txt\", \"r\", encoding='utf-8') as file:\n",
    "    textos = file.read().splitlines()\n",
    "print(\"Quantida de de sentenças no dataSet utilizado na rotulação manual:\", len(textos))\n",
    "textos = textos [0:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conveter os dados no formato IOB para uma lista "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conveter os dados no formato IOB para uma lista contendo as sentenças e uma lista contendo as tuplas com as posições da entidade e a categoria de entidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converteIOBtoSpacy(dataset_treinamento):\n",
    "    sMarker = 0 #Marcador que referência a qual setença a entidade pertence, ou seja, serve pra pegar o texto da referencia dos tokens no dataset\n",
    "    s = textos[sMarker]\n",
    "    dataSetEntradaTreinamento = []\n",
    "    entities = []\n",
    "    for index, row in dataset_treinamento.iterrows():\n",
    "        if(row['Sentenca']-1 != sMarker): # Nova sentença\n",
    "            if entities:\n",
    "                dataSetEntradaTreinamento.append((s, [tuple(e) for e in entities])) # Salva sentença anterior\n",
    "            entities = [] # esvazia entidades\n",
    "            sMarker = row['Sentenca']-1 # atualiza o marcador de sentença\n",
    "        \n",
    "            if (sMarker < len(textos)): # Limite de textos\n",
    "                s = textos[sMarker]\n",
    "            \n",
    "        if(row['Rotulo'][0] == 'O'):\n",
    "             entities.append([row['Inicio'], row['Fim'], row['Rotulo'][2:]])\n",
    "            \n",
    "        if(row['Rotulo'][0] == 'B'):\n",
    "             entities.append([row['Inicio'], row['Fim'], row['Rotulo'][2:]])\n",
    "            \n",
    "        if(row['Rotulo'][0] == 'I'):\n",
    "            if (entities): \n",
    "                entities[-1][1] = row['Fim']\n",
    "            else:\n",
    "                # print(index)\n",
    "                entities.append([row['Inicio'], row['Fim'], row['Rotulo'][2:]])\n",
    "            \n",
    "        if index == dataset_treinamento.index[-1]: # Ultimo elemento\n",
    "            if entities:\n",
    "                dataSetEntradaTreinamento.append((s, [tuple(e) for e in entities]))\n",
    "            entities = []    \n",
    "    return dataSetEntradaTreinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTreinamento = converteIOBtoSpacy(dataset_treinamento)\n",
    "## print(datasetTreinamento,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cria uma lista com as sentenças a serem rotuladas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_sentencas = []\n",
    "\n",
    "for index, item in enumerate(datasetTreinamento):\n",
    "    sentenca = item[0]\n",
    "    lista_sentencas.append(sentenca)\n",
    "len(lista_sentencas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove sentenças duplicadas\n",
    "lista_sentencas = list(dict.fromkeys(lista_sentencas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A palavra 'Taverna de Minas' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_ORGANIZACAO\n",
      "A palavra 'Velho Ferreira' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_PESSOA\n",
      "A palavra 'frutado' possui mais de um rotulacao, sao elas: \n",
      "1- CARACTERISTICA_SENSORIAL_AROMA\n",
      "2- CARACTERISTICA_SENSORIAL_SABOR\n",
      "A palavra 'Sacca' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_ORGANIZACAO\n",
      "A palavra 'SACCA' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_ORGANIZACAO\n",
      "A palavra 'baunilha' possui mais de um rotulacao, sao elas: \n",
      "1- CARACTERISTICA_SENSORIAL_AROMA\n",
      "2- CARACTERISTICA_SENSORIAL_SABOR\n",
      "A palavra 'Salinas' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_LOCAL\n",
      "2- NOME_BEBIDA\n",
      "A palavra 'amadeirado' possui mais de um rotulacao, sao elas: \n",
      "1- CARACTERISTICA_SENSORIAL_SABOR\n",
      "2- CARACTERISTICA_SENSORIAL_AROMA\n",
      "A palavra 'amadeirado' possui mais de um rotulacao, sao elas: \n",
      "1- CARACTERISTICA_SENSORIAL_SABOR\n",
      "2- CARACTERISTICA_SENSORIAL_AROMA\n",
      "A palavra 'Weber Haus' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_ORGANIZACAO\n",
      "A palavra 'Weber Haus' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_ORGANIZACAO\n",
      "A palavra 'Weber Haus' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_ORGANIZACAO\n",
      "A palavra 'Weber Haus' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_ORGANIZACAO\n",
      "A palavra 'Weber Haus' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_ORGANIZACAO\n",
      "A palavra 'Casa Bucco' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_ORGANIZACAO\n",
      "A palavra 'Casa Bucco' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_ORGANIZACAO\n",
      "A palavra 'Casa Bucco' possui mais de um rotulacao, sao elas: \n",
      "1- NOME_BEBIDA\n",
      "2- NOME_ORGANIZACAO\n",
      "A palavra 'caramelo' possui mais de um rotulacao, sao elas: \n",
      "1- CARACTERISTICA_SENSORIAL_SABOR\n",
      "2- CARACTERISTICA_SENSORIAL_AROMA\n",
      "A palavra 'frutado' possui mais de um rotulacao, sao elas: \n",
      "1- CARACTERISTICA_SENSORIAL_AROMA\n",
      "2- CARACTERISTICA_SENSORIAL_SABOR\n"
     ]
    }
   ],
   "source": [
    "dict_entidades_categorias = dict({})\n",
    "for index, item in enumerate(datasetTreinamento):\n",
    "    for dado in item[1]:\n",
    "        if dado[2] != '':\n",
    "            entidade = item[0][dado[0]:dado[1]]\n",
    "            if entidade not in dict_entidades_categorias.keys():\n",
    "                dict_entidades_categorias[entidade] = dado[2]\n",
    "            elif dado[2] != dict_entidades_categorias[entidade]:\n",
    "                print(\"A palavra '\" + str(entidade) + \"' possui mais de um rotulacao, sao elas: \\n1- \" + str(dict_entidades_categorias[entidade]) + \"\\n2- \" + str(dado[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O comando abaixo permite editar o texto da categoria de entidade nomeada. É usado para alterarmos a categoria de entidade nomeada para entidades com mais de uma categoria, haja vista que o código da linha acima seleciona a primeira entidade com sua respectiva categoria automaticamente."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dict_entidades_categorias['Taverna de Minas'] = 'NOME_BEBIDA'\n",
    "dict_entidades_categorias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforma os itens do dicionario em tuplas com pares de Entidade e Categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista_nova = list(dict_entidades_categorias.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CARACTERISTICA_SENSORIAL_AROMA',\n",
       " 'CARACTERISTICA_SENSORIAL_CONSISTÊNCIA',\n",
       " 'CARACTERISTICA_SENSORIAL_SABOR',\n",
       " 'CARACTERISTICA_SENSORIAL_COR',\n",
       " 'RECIPIENTE_ARMAZENAMENTO',\n",
       " 'EQUIPAMENTO_DESTILACAO',\n",
       " 'CLASSIFICACAO_BEBIDA',\n",
       " 'TEMPO_ARMAZENAMENTO',\n",
       " 'GRADUACAO_ALCOOLICA',\n",
       " 'TIPO_MADEIRA',\n",
       " 'NOME_BEBIDA',\n",
       " 'VOLUME',\n",
       " 'NOME_LOCAL',\n",
       " 'NOME_ORGANIZACAO',\n",
       " 'NOME_PESSOA',\n",
       " 'PRECO',\n",
       " 'TEMPO']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listaCategoriasExistentes = ['CARACTERISTICA_SENSORIAL_AROMA','CARACTERISTICA_SENSORIAL_CONSISTÊNCIA','CARACTERISTICA_SENSORIAL_SABOR', 'CARACTERISTICA_SENSORIAL_COR','RECIPIENTE_ARMAZENAMENTO','EQUIPAMENTO_DESTILACAO','CLASSIFICACAO_BEBIDA','TEMPO_ARMAZENAMENTO','GRADUACAO_ALCOOLICA','TIPO_MADEIRA','NOME_BEBIDA','VOLUME','NOME_LOCAL','NOME_ORGANIZACAO','NOME_PESSOA','PRECO','TEMPO'] \n",
    "listaFiltraPorCategorias = []\n",
    "for item in listaCategoriasExistentes:\n",
    "    listaFiltraPorCategorias.append(list(filter(lambda x: x[1] == item, lista_nova)))\n",
    "listaCategoriasExistentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_final = [[] for i in range(10)]\n",
    "\n",
    "for item in listaFiltraPorCategorias:\n",
    "    porcentagem_10 = math.ceil(len(item)*0.1)\n",
    "    random.shuffle(item)\n",
    "    for index, y in enumerate(range(0, len(item), porcentagem_10)):\n",
    "        porcentagem_10 = porcentagem_10 if porcentagem_10<len(item) else len(item)\n",
    "        lista_final[index] += item[0:porcentagem_10]\n",
    "        del item[0:porcentagem_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo que realiza a rotulação automatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metodo para rotular as entidades\n",
    "def rotulacao_entidades(lista_sentencas, pattern, dict_respostas): \n",
    "    t = [] ## lista que conterá as rotulações automaticas\n",
    "    for sentenca in lista_sentencas:\n",
    "        resultado = re.finditer(pattern, sentenca) \n",
    "        lista_aux = []\n",
    "        for iterator in resultado:\n",
    "            lista_aux.append((iterator.start(), iterator.end(), dict_respostas[iterator.group()]))\n",
    "        t.append(dict({'data': sentenca, 'label': lista_aux}))\n",
    "    return tokenizeAn(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"\"\n",
    "for index, lista in enumerate(lista_final):\n",
    "    pattern += \"|\".join(r\"\\b\" + str(re.escape(x[0])) + r\"\\b\" for x in lista)\n",
    "    t = rotulacao_entidades(lista_sentencas, pattern, dict_entidades_categorias)\n",
    "    with open(\"Resultado_com_\"+str((index+1)*10)+\"_porcento.bin\", \"wb\",encoding='utf-8') as arquivo:\n",
    "        for item in t:\n",
    "            arquivo.write(\"%s\\n\" % str(item))\n",
    "        print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

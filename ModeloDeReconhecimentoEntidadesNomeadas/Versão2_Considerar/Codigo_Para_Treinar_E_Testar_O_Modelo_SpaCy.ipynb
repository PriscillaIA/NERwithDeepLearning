{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import csv\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "from spacy.training import biluo_tags_to_spans\n",
    "from spacy.training import offsets_to_biluo_tags, biluo_tags_to_offsets, biluo_tags_to_spans\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# importações para o bloco de código do treinamento do modelo de NER\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "from spacy.tokens import Doc\n",
    "from spacy.training import Example\n",
    "import warnings\n",
    "import datetime as date\n",
    "from datetime import datetime\n",
    "import time\n",
    "from spacy.scorer import Scorer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os Dados\n",
    "Na marcação IOB o prefixo B- antes de uma tag indica que a tag é o início de um pedaço, e um prefixo I- antes de uma tag indica que a tag está dentro de um pedaço. A tag B é usada somente quando uma tag é seguida por uma tag do mesmo tipo sem tokens O entre elas. Uma tag O indica que um token não pertence a nenhuma entidade/pedaço.\n",
    "O dataset possui 5 atributos: Palavras (são os tokens que frmam a base de dados rotulada manualmente); Rotulo (são as categorias de entidades nomeadas seguidas pelo prefixo do tipo de marcação IOB; Sentenca (um número que represeta a sentença a que determinado token pertence); Inicio (número que representa o inicio de um token dentro de sua respctiva sentença); Fim (número que representa o fim de um token dentro de sua respctiva sentença)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do dataset de treinamento 129380\n"
     ]
    }
   ],
   "source": [
    "#Carrega o dataset_rotulado no formato IOB, ou seja\n",
    "dataset_treinamento = pd.read_csv(\"dataset_rotulado_treinamento.csv\", usecols=['Palavras', 'Rotulo', 'Sentenca', 'Inicio', 'Fim', 'Documento'])\n",
    "print(\"Tamanho do dataset de treinamento\",len(dataset_treinamento))\n",
    "#dataset_treinamento.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do dataset de teste 53639\n"
     ]
    }
   ],
   "source": [
    "#Carrega o dataset IOB, ou seja, os tokens são rotulados com tags do tipo marcação IOB.\n",
    "dataset_teste = pd.read_csv(\"dataset_rotulado_teste.csv\", usecols=['Palavras', 'Rotulo', 'Sentenca', 'Inicio', 'Fim','Documento'])\n",
    "print(\"Tamanho do dataset de teste\",len(dataset_teste))\n",
    "#dataset_teste.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantida de de sentenças no dataSet utilizado na rotulação manual: 13628\n"
     ]
    }
   ],
   "source": [
    "#Carrega o dataset utilizada anteriormente na rotulação manual das categorias de entidades nomeadas, sem os IDs que identificam os documentos\n",
    "#Esse arquivo é utilizado para extrairmos as setenças a que cada token rotulado no dataset pertence. \n",
    "#Essa informação é utilizada no código de conversão do dados no formato de marcação IOB para o formato compreendido pelo spaCy.\n",
    "with open(\"dataset_para_rotulacao_manual_versao_2.txt\", \"r\", encoding='utf-8') as file:\n",
    "    textos = file.read().splitlines()\n",
    "print(\"Quantida de de sentenças no dataSet utilizado na rotulação manual:\", len(textos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertendo os dados do formato IOB para o formato reconhecido pelo spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de sentenças do dataset de treinamento: 9454\n"
     ]
    }
   ],
   "source": [
    "sMarker = 0 #Marcador que referência a qual setença a entidade pertence, ou seja, serve pra pegar o texto da referencia dos tokens no dataset\n",
    "s = textos[sMarker]\n",
    "dataSetEntradaTreinamento = []\n",
    "entities = []\n",
    "for index, row in dataset_treinamento.iterrows():\n",
    "    \n",
    "    if(row['Sentenca']-1 != sMarker): # Nova sentença\n",
    "        if entities:\n",
    "            dataSetEntradaTreinamento.append((s, {\"entities\": [tuple(e) for e in entities]})) # Salva sentença anterior\n",
    "        entities = [] # esvazia entidades\n",
    "        sMarker = row['Sentenca']-1 # atualiza o marcador de sentença\n",
    "        \n",
    "        if (sMarker < len(textos)): # Limite de textos\n",
    "            s = textos[sMarker]\n",
    "            \n",
    "    if(row['Rotulo'][0] == 'O'):\n",
    "         entities.append([row['Inicio'], row['Fim'], row['Rotulo'][2:]])\n",
    "            \n",
    "    if(row['Rotulo'][0] == 'B'):\n",
    "         entities.append([row['Inicio'], row['Fim'], row['Rotulo'][2:]])\n",
    "            \n",
    "    if(row['Rotulo'][0] == 'I'):\n",
    "        if (entities): \n",
    "            entities[-1][1] = row['Fim']\n",
    "        else:\n",
    "            # print(index)\n",
    "            entities.append([row['Inicio'], row['Fim'], row['Rotulo'][2:]])\n",
    "            \n",
    "    if index == dataset_treinamento.index[-1]: # Ultimo elemento\n",
    "        if entities:\n",
    "            dataSetEntradaTreinamento.append((s, {\"entities\": [tuple(e) for e in entities]}))\n",
    "        entities = [] \n",
    "\n",
    "print('Quantidade de sentenças do dataset de treinamento:', len(dataSetEntradaTreinamento))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de sentenças do dataset de teste: 4174\n"
     ]
    }
   ],
   "source": [
    "sMarker = 0 #Marcador que referência a qual setença a entidade pertence, ou seja, serve pra pegar o texto da referencia dos tokens no dataset\n",
    "s = textos[sMarker]\n",
    "dataSetEntradaTeste = []\n",
    "entities = []\n",
    "for index, row in dataset_teste.iterrows():\n",
    "    \n",
    "    if(row['Sentenca']-1 != sMarker): # Nova sentença\n",
    "        if entities:\n",
    "            dataSetEntradaTeste.append((s, {\"entities\": [tuple(e) for e in entities]})) # Salva sentença anterior\n",
    "        entities = [] # esvazia entidades\n",
    "        sMarker = row['Sentenca']-1 # atualiza o marcador de sentença\n",
    "        \n",
    "        if (sMarker < len(textos)): # Limite de textos\n",
    "            s = textos[sMarker]\n",
    "            \n",
    "    if(row['Rotulo'][0] == 'O'):\n",
    "         entities.append([row['Inicio'], row['Fim'], row['Rotulo'][2:]])\n",
    "            \n",
    "    if(row['Rotulo'][0] == 'B'):\n",
    "         entities.append([row['Inicio'], row['Fim'], row['Rotulo'][2:]])\n",
    "            \n",
    "    if(row['Rotulo'][0] == 'I'):\n",
    "        if (entities): \n",
    "            entities[-1][1] = row['Fim']\n",
    "        else:\n",
    "            # print(index)\n",
    "            entities.append([row['Inicio'], row['Fim'], row['Rotulo'][2:]])\n",
    "            \n",
    "    if index == dataset_teste.index[-1]: # Ultimo elemento\n",
    "        if entities:\n",
    "            dataSetEntradaTeste.append((s, {\"entities\": [tuple(e) for e in entities]}))\n",
    "        entities = [] \n",
    "\n",
    "print('Quantidade de sentenças do dataset de teste:', len(dataSetEntradaTeste))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Dividindo a base em treino e teste\n",
    "TRAIN_DATA,TEST_DATA =  train_test_split(dataSetEntrada, train_size=0.70, shuffle=True)\n",
    "print('Quantidade de dados para treino do modelo:',len(TRAIN_DATA))\n",
    "print('Quantidade de dados para teste do modelo:',len(TEST_DATA))\n",
    "\n",
    "TEST_DATA, VALIDATION_DATA = train_test_split(TEST_DATA, train_size=0.90, shuffle=True)\n",
    "print('Quantidade de dados validação durante o treinamento:',len(VALIDATION_DATA))\n",
    "#print('Quantidade de dados para teste do modelo:',len(TEST_DATA))\n",
    "\n",
    "#TRAIN_DATA = dataSetEntrada[0:300]\n",
    "#TEST_DATA = dataSetEntrada[301:400]\n",
    "#VALIDATION_DATA = dataSetEntrada[302:322]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado '<spacy.lang.pt.Portuguese object at 0x0000028A8068DCD0>'\n"
     ]
    }
   ],
   "source": [
    "# Carregando um modelo do spaCy em portguês previamente treinando\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "print (\"Modelo carregado '% s'\"% nlp)\n",
    "\n",
    "##carregando um modelo em braco\n",
    "#nlp = spacy.blank('pt')\n",
    "#nlp.vocab.vectors.name = 'spacy_pretrained_vectors'\n",
    "#print (\"Modelo carregado '% s'\"% nlp)\n",
    "#ner = nlp.create_pipe('ner')\n",
    "#nlp.add_pipe('ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizando o Tokenizador para o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.char_classes import LIST_PUNCT, LIST_ELLIPSES, LIST_QUOTES, LIST_CURRENCY, LIST_HYPHENS\n",
    "from spacy.lang.char_classes import LIST_ICONS, HYPHENS, CURRENCY\n",
    "from spacy.lang.char_classes import CONCAT_QUOTES, ALPHA_LOWER, ALPHA_UPPER, ALPHA\n",
    "\n",
    "# Essa função cria um objeto customizado da classe Tokenizer do spacy, para alinhamento dos tokens com a rotulações em alguns casos especiais por exemplo: '-' e '$'.\n",
    "def custom_tokenizer(nlp):    \n",
    "    infixes = (\n",
    "        spacy.lang.char_classes.LIST_ELLIPSES\n",
    "        + spacy.lang.char_classes.LIST_ICONS\n",
    "        + [\"\\.\", \"\\/\", \":\", \"\\(\", \"\\)\"]\n",
    "        + [\n",
    "            r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n",
    "            r\"(?<=[\\.])[\\.](?=[\\.])\",\n",
    "            r\"(?<=[{a}{q}])\\.(?=[{a}{q}])\".format(\n",
    "                a = ALPHA, q = CONCAT_QUOTES),\n",
    "            r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
    "            r\"(?<=[{a}])(?:{h}|\\/)(?=[{a}])\".format(a=ALPHA, h=LIST_HYPHENS),\n",
    "            r\"(?<=[{a}])(?:{h}|\\/)(?=[0-9])\".format(a=ALPHA, h=LIST_HYPHENS),\n",
    "            r\"(?<=[0-9])(?:{h}|\\/)(?=[{a}])\".format(a=ALPHA, h=LIST_HYPHENS),\n",
    "            r\"(?<=[0-9])(?:{h}|\\/|,|\\.)(?=[0-9])\".format(a=ALPHA, h=LIST_HYPHENS),\n",
    "            r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
    "            r\"(?<=[{a}\\\"]),(?=[0-9{a}])\".format(a=ALPHA),\n",
    "        ]\n",
    "    )\n",
    "    list_quotes = [\"\\\\'\", '\"', '`',\n",
    "                     '‘', '´', '’', '‚', ',',\n",
    "                     '„', '»', '«', '「', '」',\n",
    "                     '『', '』', '（', '）', '〔',\n",
    "                     '〕', '【', '】', '《', '》',\n",
    "                     '〈', '〉']\n",
    "    suffixes = (\n",
    "        LIST_PUNCT\n",
    "        + LIST_HYPHENS\n",
    "        + list_quotes\n",
    "        + LIST_ICONS\n",
    "        + [ \"\\/\", \":\", \"\\(\", \"\\)\"]\n",
    "        + [\"'s\", \"'S\", \"’s\", \"’S\", \"—\", \"–\"]\n",
    "        + [\n",
    "            r\"(?<=[0-9])\\+\",\n",
    "            r\"(?<=[0-9])(?:{c})\".format(c=CURRENCY),\n",
    "            r\"(?<=[0-9a-z(?:{q})])\\.\".format(\n",
    "            al=ALPHA_LOWER, q=CONCAT_QUOTES),\n",
    "            r\"(?<=[{au}])\\.\".format(au=ALPHA_UPPER),\n",
    "        ] \n",
    "    )\n",
    "    \n",
    "    prefixes = (\n",
    "        LIST_PUNCT\n",
    "        + [ \"\\/\", \":\", \"\\(\", \"\\)\"]\n",
    "        + LIST_HYPHENS\n",
    "        + list_quotes\n",
    "        + LIST_CURRENCY\n",
    "        + LIST_ICONS\n",
    "    )\n",
    "\n",
    "    infix_re = spacy.util.compile_infix_regex(infixes)\n",
    "    suffix_re = spacy.util.compile_suffix_regex(suffixes)\n",
    "    prefix_re = spacy.util.compile_prefix_regex(prefixes)\n",
    "    custom = Tokenizer(nlp.vocab, prefix_search=prefix_re.search,\n",
    "                                suffix_search=suffix_re.search,\n",
    "                                infix_finditer=infix_re.finditer,\n",
    "                                token_match=nlp.tokenizer.token_match,\n",
    "                                rules=None)\n",
    "    special_case = [{ORTH: \".\"}, {ORTH: \".\"}, {ORTH: \".\"}]        # Adicionando uma regra especial\n",
    "    custom.add_special_case(\"...\", special_case)\n",
    "    return custom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py:1002: FutureWarning: Possible set difference at position 8131\n",
      "  return re.compile(expression)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py:1002: FutureWarning: Possible set difference at position 8137\n",
      "  return re.compile(expression)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py:1002: FutureWarning: Possible set difference at position 10405\n",
      "  return re.compile(expression)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py:1002: FutureWarning: Possible set difference at position 10411\n",
      "  return re.compile(expression)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py:1002: FutureWarning: Possible set difference at position 10471\n",
      "  return re.compile(expression)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py:1002: FutureWarning: Possible set difference at position 10477\n",
      "  return re.compile(expression)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py:1002: FutureWarning: Possible set difference at position 11641\n",
      "  return re.compile(expression)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spacy\\util.py:1002: FutureWarning: Possible set difference at position 11647\n",
      "  return re.compile(expression)\n"
     ]
    }
   ],
   "source": [
    "# atribuindo o tokenizador customizado ao modelo nlp\n",
    "nlp.tokenizer = custom_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurando parâmetros e dados para o treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtendo o componente do pipeline (ner) para trabalhar com reconhecimentos de entidades nomeadas\n",
    "ner = nlp.get_pipe('ner')\n",
    "# Adicionando as categorias de entidade nomeada ao pipeline 'ner' manualmente\n",
    "ner.add_label('CARACTERISTICA_SENSORIAL_AROMA')\n",
    "ner.add_label('CARACTERISTICA_SENSORIAL_CONSISTÊNCIA')\n",
    "ner.add_label('CARACTERISTICA_SENSORIAL_SABOR')\n",
    "ner.add_label('CARACTERISTICA_SENSORIAL_COR')\n",
    "ner.add_label('RECIPIENTE_ARMAZENAMENTO')\n",
    "ner.add_label('EQUIPAMENTO_DESTILACAO')\n",
    "ner.add_label('CLASSIFICACAO_BEBIDA')\n",
    "ner.add_label('TEMPO_ARMAZENAMENTO')\n",
    "ner.add_label('GRADUACAO_ALCOOLICA')\n",
    "ner.add_label('TIPO_MADEIRA')\n",
    "ner.add_label('NOME_BEBIDA')\n",
    "ner.add_label('VOLUME')\n",
    "ner.add_label('NOME_LOCAL')\n",
    "ner.add_label('NOME_ORGANIZACAO')\n",
    "ner.add_label('NOME_PESSOA')\n",
    "ner.add_label('PRECO')\n",
    "ner.add_label('TEMPO')\n",
    "\n",
    "#print(\"Categorias de entidade que o modelo contém:\", '\\n\\n', ner.label_data)\n",
    "# outra maneira mais rápida de adicionar as categorias de entidades ao 'ner'\n",
    "#ner = nlp.get_pipe('ner')\n",
    "#for texto, annotations in TRAIN_DATA:\n",
    "    #for ent in annotations.get(\"entities\"):\n",
    "        #ner.add_label(ent[2])     \n",
    "        #print(ent[2])\n",
    "#print(\"Categorias de entidade que o modelo contém:\", '\\n\\n', ner.label_data) #verificando as categorias de entidades nomeadas contidas no pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo os nomes dos componentes que queremos desativar durante o treinamento\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "#Abaixo temos outra maneira de fazer a mesma cois, mas com duas linhas de comando\n",
    "#pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "#unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tranforma os dados do conjunto de treino no formato entendido pelo modelo ner\n",
    "examples_train = []\n",
    "for text, annots in dataSetEntradaTreinamento:\n",
    "    examples_train.append(Example.from_dict(nlp.make_doc(text), annots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando o modelo de reconhecimento de entidades nomeadas\n",
    "O código abaixo realiza o treinamento do modelo de reconhecimento de entidades nomeadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perda acumulada do modelo ({'ner': 76302.78457618949}) \n",
      "\n",
      "Tempo gasto para treinar o modelo em segundos --> 596.2787725925446 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#VTreinamento do modelo ner com novas categorias de entidades nomeadas\n",
    "import decimal\n",
    "optimizar = nlp.create_optimizer() #quando utilizamos o modelo já treinado do spaCy\n",
    "#optimizar = nlp.begin_training() #quando é criado um modelo nlp vazio\n",
    "epochsSize = 10\n",
    "batchSize = 128\n",
    "drop_size = 0.25\n",
    "losses = {}\n",
    "with nlp.disable_pipes(*unaffected_pipes), warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"once\", category=UserWarning, module='spacy') \n",
    "    start_epoch = time.time()\n",
    "    for epoch in range(epochsSize):\n",
    "        random.shuffle(examples_train)\n",
    "        #count = 0\n",
    "        for batch in minibatch(examples_train, size=batchSize):\n",
    "            nlp.update(batch, losses=losses, drop=drop_size, sgd=optimizar) \n",
    "            and_epoch = time.time()            \n",
    "            #count+=1\n",
    "            #valorPerda = losses['ner'] # valorPerda = decimal.Decimal(losses['ner'])\n",
    "            #print(\"Perda acumulada ({}) para o batch ({})\" .format(valorPerda,count,\"\\n\"))\n",
    "            tempoParaTreinarModelo = and_epoch-start_epoch \n",
    "            #metricas = nlp.evaluate(examples_validation)\n",
    "            #print('Métricas de validação do modelo para o batch {}'.format(count),'\\n')\n",
    "            #print(metricas,'\\n')\n",
    "\n",
    "        #print(\"Perda acumulada ({}) para a epóca ({} de {})\" .format(losses, epoch + 1, epochsSize),'\\n') \n",
    "    print(\"Perda acumulada do modelo ({})\" .format(losses),\"\\n\")\n",
    "    print('Tempo gasto para treinar o modelo em segundos -->', tempoParaTreinarModelo,'\\n')\n",
    "    #metricas=nlp.evaluate(examples_validation)\n",
    "    #print('Métricas Final de validação do modelo com {} épocas e {} batchs'.format(epochsSize),'\\n') \n",
    "    #print(metricas,'\\n') \n",
    "    #scorer = Scorer()\n",
    "    #result=scorer.score(examples)\n",
    "    #print('SCORER POR BATC:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação Rotulação Manual versus Rotulação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tranforma os dados do conjunto de teste no formato entendido pelo modelo ner\n",
    "examples_test = []\n",
    "for text, annots in dataSetEntradaTeste:\n",
    "    examples_test.append(Example.from_dict(nlp.make_doc(text), annots))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "import collections\n",
    "# Compara item por item como o modelo classificou as sentenças e como elas foram classificadas manual (ponto de referencia).\n",
    "#nlp = spacy.load(output_dir)\n",
    "examples = []\n",
    "comparacao= []\n",
    "for text, annots in dataSetEntradaTeste:\n",
    "    doc = nlp(text)\n",
    "    #doc = nlp.make_doc(text)\n",
    "    #spacy.displacy.render(nlp(text))  \n",
    "    #print('Texto:', text,'\\n')\n",
    "    anotacao_manual = annots['entities']\n",
    "   # print('Texto-->', text,'\\n')\n",
    "    print(f'Classificação Manual:', anotacao_manual,'\\n')\n",
    "    result_model = [(item.start_char, item.end_char,item.label_) for item in doc.ents]\n",
    "    #print(f'Classificação do Modelo:', result_model,'\\n')\n",
    "    \n",
    "    '''for item in doc.ents:\n",
    "        print(item)\n",
    "        print('Model prediction: ', 'entities: ', [(item.start_char, item.end_char,item.label_)],'\\n')'''       \n",
    "    #examples.append(Example.from_dict(doc, annots)) \n",
    "    #print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc],'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas Precision, Recall e f-measure: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'pos_acc': None, 'morph_acc': None, 'morph_per_feat': None, 'sents_p': 1.0, 'sents_r': 1.0, 'sents_f': 1.0, 'dep_uas': None, 'dep_las': None, 'dep_las_per_type': None, 'ents_p': 0.8772459196269373, 'ents_r': 0.8653768096333379, 'ents_f': 0.8712709440130773, 'ents_per_type': {'NOME_BEBIDA': {'p': 0.8, 'r': 0.7908902691511387, 'f': 0.795419052576783}, 'PRECO': {'p': 0.856140350877193, 'r': 0.9070631970260223, 'f': 0.8808664259927799}, 'VOLUME': {'p': 0.9726027397260274, 'r': 0.9281045751633987, 'f': 0.9498327759197325}, 'GRADUACAO_ALCOOLICA': {'p': 0.9667590027700831, 'r': 0.9748603351955307, 'f': 0.9707927677329623}, 'TIPO_MADEIRA': {'p': 0.9489144316730523, 'r': 0.9138991389913899, 'f': 0.931077694235589}, 'TEMPO_ARMAZENAMENTO': {'p': 0.900497512437811, 'r': 0.9329896907216495, 'f': 0.9164556962025316}, 'NOME_ORGANIZACAO': {'p': 0.8480565371024735, 'r': 0.75, 'f': 0.7960199004975125}, 'NOME_LOCAL': {'p': 0.9333849728892332, 'r': 0.948072383949646, 'f': 0.9406713505074162}, 'RECIPIENTE_ARMAZENAMENTO': {'p': 0.8910256410256411, 'r': 0.9266666666666666, 'f': 0.9084967320261438}, 'CARACTERISTICA_SENSORIAL_SABOR': {'p': 0.5811320754716981, 'r': 0.555956678700361, 'f': 0.5682656826568266}, 'CARACTERISTICA_SENSORIAL_COR': {'p': 0.8609271523178808, 'r': 0.8666666666666667, 'f': 0.8637873754152824}, 'TEMPO': {'p': 0.9640102827763496, 'r': 0.9168704156479217, 'f': 0.9398496240601505}, 'CLASSIFICACAO_BEBIDA': {'p': 0.8381642512077294, 'r': 0.8032407407407407, 'f': 0.8203309692671394}, 'CARACTERISTICA_SENSORIAL_AROMA': {'p': 0.5947955390334573, 'r': 0.5693950177935944, 'f': 0.5818181818181819}, 'CARACTERISTICA_SENSORIAL_CONSISTÊNCIA': {'p': 0.8658536585365854, 'r': 0.8352941176470589, 'f': 0.8502994011976048}, 'NOME_PESSOA': {'p': 0.8284518828451883, 'r': 0.8918918918918919, 'f': 0.8590021691973969}, 'EQUIPAMENTO_DESTILACAO': {'p': 0.825, 'r': 0.7764705882352941, 'f': 0.8}}, 'tag_acc': None, 'lemma_acc': None, 'speed': 4144.520575556801}\n"
     ]
    }
   ],
   "source": [
    "# Apresenta o resultados das métricas para o modelo como um todo, e as métricas do modelo para cada categoria de entidade\n",
    "calculatedBySpacy = nlp.evaluate(examples_test)\n",
    "print(calculatedBySpacy)\n",
    "\n",
    "#from spacy.scorer import Scorer\n",
    "#scorer = Scorer()   \n",
    "#example_scores = []\n",
    "#for text, annot in dataSetEntradaTeste:\n",
    "#    print(text)\n",
    "#    pred = nlp.make_doc(text)\n",
    "#    temp = Example.from_dict(pred, annot)\n",
    "#    example_scores.append(temp)\n",
    "#    scores = scorer.score(example_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação do Modelo pela Métrica Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary which will be populated with the entities and result information\n",
    "entity_evaluation = {}\n",
    "# helper function to udpate the entity_evaluation dictionary\n",
    "def update_results(entity, metric):\n",
    "    if entity not in entity_evaluation:\n",
    "        entity_evaluation[entity] = {\"correct\": 0, \"total\": 0}  \n",
    "    entity_evaluation[entity][metric] += 1\n",
    "    \n",
    "# same as before, see if entities from test set match what spaCy currently predicts\n",
    "example_scores = []\n",
    "for data in dataSetEntradaTeste:\n",
    "    sentence = data[0]\n",
    "    entities = data[1][\"entities\"]\n",
    "    for entity in entities:\n",
    "        doc = nlp(sentence)\n",
    "        correct_text = sentence[entity[0]:entity[1]]\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == entity[2] and ent.text == correct_text:\n",
    "                update_results(ent.label_, \"correct\")\n",
    "                break\n",
    "        update_results(entity[2], \"total\")\n",
    "\n",
    "print(\"Dados corretamente classificados versus total de dados corretos:\",'\\n', entity_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculo Acuracia por Categoria e Acuracia Total\")\n",
    "sum_total = 0\n",
    "sum_correct = 0\n",
    "sum_incorretos_total = 0\n",
    "accuracy_by_category = {}\n",
    "\n",
    "for entity in entity_evaluation:\n",
    "    if entity != '':\n",
    "        total = entity_evaluation[entity][\"total\"]\n",
    "        correct = entity_evaluation[entity][\"correct\"]\n",
    "        rotulados_incorretamente = total-correct\n",
    "        sum_total += total\n",
    "        sum_correct += correct\n",
    "        sum_incorretos_total += rotulados_incorretamente\n",
    "        percentual_acertos_modelo_por_categoria = correct/total\n",
    "        #total_acerto_por_categoria = sum_accuracy_total\n",
    "        print(\"{} --> {:.2f}%\".format(entity, percentual_acertos_modelo_por_categoria))\n",
    "        \n",
    "        accuracy_by_category[entity] = {str(percentual_acertos_modelo_por_categoria)}#para salvar no arquivo .txt com o percentual\n",
    "sum_accuracy = sum_correct / sum_total \n",
    "sum_accuracy_total = str(sum_accuracy) #para salvar no arquivo .txt com o percentual\n",
    "\n",
    "print(\"Acuracia Total (todas as categorias): {:.2f}%\".format(sum_accuracy))\n",
    "print('Total de entidades Rotulados Manualmente (referencia):', sum_total)\n",
    "print('Total de entidades Rotuladas Corretamente pelo modelo:', sum_correct)\n",
    "print('Total de entidades Rotuladas Incorretamente pelo modelo:', sum_incorretos_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvados os resultados em um arquivo de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando informações relevantes em um arquivo.txt\n",
    "nome_arquivo = '  128epochs64batchs.txt'\n",
    "with open ('./ResultadosDosTestes/'+nome_arquivo,\"w\", encoding='utf-8')  as output:\n",
    "    quantidadeDados = str(len(dataSetEntradaTeste))\n",
    "    output.write('Tamanho do dataset de teste: '+quantidadeDados)\n",
    "    output.write('\\n') \n",
    "    \n",
    "    output.write('\\n'+\"|CONFIGURAÇÕES UTILIZADAS PARA TREINAR O MODELO:|\"+'\\n')\n",
    "    epochsSize_String = str(epochsSize)\n",
    "    batchSize_String = str(batchSize)\n",
    "    drop_String = drop_size\n",
    "    output.write('Total de épocas: '+epochsSize_String+\"\\n\")\n",
    "    output.write('Total de batches: '+batchSize_String+\"\\n\")\n",
    "    output.write('Tamanho do Drop:')\n",
    "    output.write(str(drop_size))\n",
    "    output.write('\\n') \n",
    "                 \n",
    "    #Informações sobre treinamento do modelo\n",
    "    output.writelines('\\n'+\"|INFORMAÇÕES SOBRE TREINAMENTO DO MODELO:|\"+'\\n')\n",
    "    output.writelines('Perda acumulada do modelo (soma de todas as perdas): '+str(losses))\n",
    "    output.write('\\n')\n",
    "    output.writelines('Tempo gasto para treinar o modelo em segundos: '+str(tempoParaTreinarModelo))\n",
    "    output.write('\\n') \n",
    "    \n",
    "    #Métricas geradas pelo método 'evaluat', disponibilizado pelo próprio spaCy.\n",
    "    output.writelines('\\n'+\"|RESULTADOS DO MODELO PARA OS DADOS DO DATASET DE TESTE|\")    \n",
    "    output.writelines('\\n'+\"|Abaixo temos Precison, Recall, F-measure e Acuracia Geral:|\"+'\\n')\n",
    "    ents_p = \"Precisão Total: \"+str(round(calculatedBySpacy.get(\"ents_p\"),4))+'\\n'\n",
    "    ents_r = \"Revocação Total: \"+str(round(calculatedBySpacy.get(\"ents_r\"),4))+'\\n'\n",
    "    ents_f = \"F-measure Total: \"+str(round(calculatedBySpacy.get(\"ents_f\"),4))+'\\n'\n",
    "    ents_a = \"Acurácia Total: \"+str(round(sum_accuracy,4))+'\\n'\n",
    "    total_dados_com_rotulos = \"Total de entidades rotuladas existentes no dataset de teste: \"+str(round(sum_total,2))+'\\n'\n",
    "    total_dados_rotulados_corretamento = \"Total de entidades classificadas corretamente pelo modelo: \"+str(round(sum_correct,2))+'\\n'\n",
    "    total_dados_rotulados_incorretamentos = \"Total de entidades classificadas incorretamente pelo modelo: \"+str(round(sum_incorretos_total,2))+'\\n'\n",
    "    \n",
    "    output.write(ents_p),output.write(ents_r),output.write(ents_f),output.write(ents_a)\n",
    "    output.write(total_dados_com_rotulos),output.write(total_dados_rotulados_corretamento)\n",
    "    output.write(total_dados_rotulados_incorretamentos)\n",
    "    #output.writelines(';'.join(str(x) for x in (token_acc,token_p)))\n",
    "    \n",
    "    output.writelines('\\n'+\"|Abaixo temos Precision, Recall e F-measure para cada categoria:|\"+'\\n')\n",
    "    ents_per_type = calculatedBySpacy.get(\"ents_per_type\")\n",
    "    for key in ents_per_type:\n",
    "        ents_por_tipo = str(key)+str(ents_per_type[key])+'\\n'\n",
    "        output.write(ents_por_tipo) \n",
    "   \n",
    "    #Acuracia do modelo por categoria.\n",
    "    output.writelines('\\n'+\"|Abaixo temos a Acurácia para cada categoria:|\"+'\\n')\n",
    "    for key in accuracy_by_category:\n",
    "        entity_evaluation_accuracy = str(key)+str(accuracy_by_category[key])+'\\n'\n",
    "        output.write(entity_evaluation_accuracy)\n",
    "    \n",
    "    #Total de acertos e erros do modelo por categoria.    \n",
    "    output.writelines('\\n'+\"|Abaixo temos o total de acertos do modelo para cada categoria Versus o total que ele deveria classificar:|\"+'\\n')\n",
    "    for key in entity_evaluation:\n",
    "        if key != '':\n",
    "            acertos_erros = str(key)+str(entity_evaluation[key])+'\\n'\n",
    "            output.write(acertos_erros)\n",
    "            \n",
    "    #Parametros digitados no terminal pelo usuario\n",
    "    #output.write('\\n'+\"|ABAIXO TEMOS OS PARAMETROS INFORMADOS NO TEMRINAL:|\"+'\\n')\n",
    "    #output.writelines(';'.join(str(x) for x in (primeiraEntradaTerminal,segundaEntradaTerminal,terceiraEntradaTerminal,quartaEntradaTerminal,quintaEntradaTerminal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the  model to directory\n",
    "nome_modelo = '128epochs64batchs'\n",
    "from pathlib import Path\n",
    "output_dir=Path('./ResultadosDosTestes/'+nome_modelo)\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Modelo salvo!\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and predict\n",
    "\n",
    "#print(\"Loading from\", output_dir)\n",
    "#nlp_updated = spacy.load(output_dir)\n",
    "#doc = nlp_updated(\"Eu gostei da Cachaça Artesanal criada em Minas Gerais\" )\n",
    "#print(\"Entidades\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
